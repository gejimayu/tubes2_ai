{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Tugas Besar 2 Intelijensi Buatan **\n",
    "\n",
    "** Prediksi Income per Tahun **\n",
    "** Website http://predicio.herokuapp.com/ **\n",
    "\n",
    "** Anggota Kelompok: **\n",
    "- Devin Alvaro / 13515062\n",
    "- Stevanno Hero Leadervand / 13515082\n",
    "- Rizki Ihza / 13515104\n",
    "- Gianfranco Fertino Hwandiano / 13515118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing, neighbors, tree\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membaca dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/CencusIncome.data.txt\", header = None)\n",
    "temp = pd.read_csv(\"data/CencusIncome.data.txt\", header = None)\n",
    "# name columns\n",
    "train_df = train_df.rename(columns={0: 'age', 1: 'workclass', 2: 'fnlwgt', 3: 'education', 4: 'education-num', 5: 'marital-status', 6: 'occupation',7: 'relationship', 8: 'race',9: 'sex', 10: 'capital-gain', 11: 'capital-loss', 12: 'hours-per-week', 13: 'native-country', 14: 'label'})\n",
    "temp = temp.rename(columns={0: 'age', 1: 'workclass', 2: 'fnlwgt', 3: 'education', 4: 'education-num', 5: 'marital-status', 6: 'occupation',7: 'relationship', 8: 'race',9: 'sex', 10: 'capital-gain', 11: 'capital-loss', 12: 'hours-per-week', 13: 'native-country', 14: 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for column in temp:\n",
    "    le.fit(temp[column])\n",
    "    temp[column] = le.transform(temp[column])\n",
    "\n",
    "y = np.array(temp['label'])\n",
    "x = np.array(temp.drop(['label'], 1))\n",
    "\n",
    "#feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 1)\n",
    "fit = rfe.fit(x, y)\n",
    "print(\"Feature Ranking: \")\n",
    "print(fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection merupakan metode untuk memilih subset atribut-atribut/features dari dataset yang dirasa penting saja. Manfaatnya diantara lain yaitu meningkatkan akurasi model dan mempercepat proses training karena data menjadi lebih sedikit.\n",
    "\n",
    "Metode feature selection yang kelompok kami gunakan yaitu Recursive Feature Elemination (RFE). Metode ini mengurutkan atribut-atribut (ranking) dari urutan 1 (paling penting) hingga seterusnya (semakin tidak penting). \n",
    "\n",
    "Dari informasi di atas, dapat disimpulkan bahwa fnlwgt (atribut nomor 3 dari kiri) merupakan atribut yang paling tidak penting (urutan terakhir yaitu 14) jika dibandingkan dengan atribut-atribut lainnya. Berdasarkan hal tersebut, kami memilih untuk tidak mengikutkan atribut fnlwgt pada training model kami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove 'fnlwgt' column\n",
    "train_df = train_df.drop(['fnlwgt'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Missing Value Treatment **\n",
    "\n",
    "Dari dataset, kami melihat bahwa ada sekitar 4000 baris data yang mengandung missing value, ditandai dengan tanda ?. \n",
    "\n",
    "Kami telah melakukan berbagai eksplorasi tentang bagaimana menghandle hal tersebut. \n",
    "\n",
    "Kami telah mencoba menghapus data yang bersangkutan dan juga mengganti value ? dengan value modus ataupun rata2 dari atribut yang bersangkutan. \n",
    "\n",
    "Namun, semua hal tersebut tidak meningkatkan akurasi dari model kami, malah justru menurunkan akurasi. Jadi, kami memutuskan untuk membiarkan value tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding data dengan One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(train_df['label'])\n",
    "train_df['label'] = le.transform(train_df['label'])\n",
    "\n",
    "train_df = pd.get_dummies(train_df)\n",
    "\n",
    "y = np.array(train_df['label'])\n",
    "x = np.array(train_df.drop(['label'], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** One-Hot Encoding **\n",
    "\n",
    "Pada dataset yang diberikan, terdapat nilai-nilai berupa string (bukan angka), sehingga harus dilakukan pemrosesan (*encoding*) agar nilai-nilai string tersebut menjadi angka yang dapat dikalkulasi oleh algoritma-algoritma *learning* menjadi model.\n",
    "\n",
    "Untuk *preprocessing* dataset ini, kami memilih *one-hot encoding*, yaitu *preprocessing* yang mentransformasi nilai-nilai pada setiap kolom bernilai string menjadi kolomnya masing-masing. Kemudian, pada tiap kolom baru ini terdapat nilai biner (1 atau 0) yang menandakan suatu data berada dalam kategori bernilai demikian atau bukan.\n",
    "\n",
    "Sebagai contoh, terdapat kolom Sex dengan nilai Male dan Female. Kemudian, kolom Sex ini ditransformasi menjadi 2 kolom, yaitu kolom Male dan Female. Untuk suatu data bernilai Male, maka nilai di kolom Male adalah 1 dan di kolom Female adalah 0. Berlaku pula kebalikannya untuk data bernilai Female.\n",
    "\n",
    "Kami memilih *one-hot encoding* karena nilai-nilai berbentuk string pada dataset ini tidak tepat bila diubah menjadi angka. Misalnya saja bila pada kolom Race, nilai Asian menjadi 0, White menjadi 1, dan Black menjadi 2, menjadi tidak benar karena menandakan suatu ras bernilai lebih tinggi atau rendah dari ras lain.\n",
    "\n",
    "*One-hot encoding* ini memang memiliki kelemahan yaitu menambah jumlah kolom secara signifikan sehingga meningkatkan kompleksitas algoritma *learning* yang ada, namun masih dapat ditoleransi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eksperimen untuk mendapatkan model terbaik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "score = cross_val_score(gnb, x, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Fold-\" + str(i + 1) + \":\", \"%0.6f\" % score[i])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Mean: %0.6f\" % score.mean())\n",
    "print(\"Accuration: %0.6f (+/- %0.6f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID3learn = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "score = cross_val_score(ID3learn, x, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Fold-\" + str(i + 1) + \":\", \"%0.6f\" % score[i])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Mean: %0.6f\" % score.mean())\n",
    "print(\"Accuration: %0.6f (+/- %0.6f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = 61\n",
    "\n",
    "KNNlearn = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "\n",
    "score = cross_val_score(KNNlearn, x, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Fold-\" + str(i + 1) + \":\", \"%0.6f\" % score[i])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Mean: %0.6f\" % score.mean())\n",
    "print(\"Accuration: %0.6f (+/- %0.6f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLPlearn = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(5, 2))\n",
    "\n",
    "score = cross_val_score(MLPlearn, x, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Fold-\" + str(i + 1) + \":\", \"%0.6f\" % score[i])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Mean: %0.6f\" % score.mean())\n",
    "print(\"Accuration: %0.2f (+/- %0.6f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Memilih model terbaik **\n",
    "\n",
    "setelah dilakukan percobaan learning dengan beberapa algoritma yaitu:\n",
    "\n",
    "- Naive Bayes\n",
    "- Decision Tree Learning\n",
    "- K-Nearest neighbours\n",
    "- Multilayer Perceptron\n",
    "\n",
    "didapat model yang memiliki akurasi tertinggi untuk dataset ini adalah model\n",
    "K-Nearest neighbours. Oleh karena itu dipilih model K-Nearest neighbour untuk\n",
    "digunakan dalam perhitungan selanjutnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNlearn = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "KNNlearn.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(KNNlearn, 'model/best.pkl')\n",
    "joblib.dump(KNNlearn, '../webapp/model/best.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Loading* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNNlearn = joblib.load('model/best.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi dan prediksi dengan model terpilih"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membaca test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"data/CencusIncome.test.txt\", header=None, skiprows=1)\n",
    "\n",
    "# name columns\n",
    "test_df = test_df.rename(columns={0: 'age', 1: 'workclass', 2: 'fnlwgt', 3: 'education', 4: 'education-num', 5: 'marital-status', 6: 'occupation',7: 'relationship', 8: 'race',9: 'sex', 10: 'capital-gain', 11: 'capital-loss', 12: 'hours-per-week', 13: 'native-country', 14: 'label'})\n",
    "\n",
    "# remove 'fnlwgt' column\n",
    "test_df = test_df.drop(['fnlwgt'], axis=1)\n",
    "\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Preprocessing* test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(test_df['label'])\n",
    "test_df['label'] = le.transform(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(test_df)\n",
    "\n",
    "missing_columns = set(train_df.columns) - set(test_df.columns)\n",
    "for column in missing_columns:\n",
    "    test_df[column] = 0\n",
    "\n",
    "y = np.array(test_df['label'])\n",
    "x = np.array(test_df.drop(['label'], 1))\n",
    "\n",
    "print(np.shape(y))\n",
    "print(np.shape(x))\n",
    "\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hasil prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = KNNlearn.score(x, y)\n",
    "print(\"Accuracy: \", score * 100 ,\"%\")\n",
    "\n",
    "y_pred = KNNlearn.predict(x)\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
